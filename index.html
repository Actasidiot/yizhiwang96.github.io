<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yizhi Wang</title>
  
  <meta name="author" content="Yizhi Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yizhi Wang (ÁéãÈÄ∏‰πã)</name>
              </p>
              <p>I am currently a PhD candidate in the Wangxuan Institute of Computer Technology (WICT), Peking University, where I work on Computer Vision and Computer Graphics.
              </p>
              <p>
                During my PhD, I am focused on applying deep generative models to analyze and synthesize 2D geometric data (e.g., glyph, font, and layout). I am supervised by Prof. <a href="https://www.icst.pku.edu.cn/zlian/">Zhouhui Lian</a> and Prof. <a href="https://scholar.google.com/citations?user=Ox427jAAAAAJ&hl=en&oi=ao">Jianguo Xiao</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:wangyizhi@pku.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/yizhi_wang_s_CV_2022_0323.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=0S3NCzUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://yizhiwang96.github.io/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yizhi_wang_s_selfie.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/yizhi_wang_s_selfie.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I have strong interests in designing image/graphics generation models and facilitating visual recognition tasks with them. Specifically, my researching projects cover the following topics: Glyph Image Synthesis, Vector Font Generation, Layout Generation, Scene Text (Character) Recognition and Detection, Font Recognition, etc. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/cvpr22_textlogolayout.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://hologerry.github.io/Attr2Font/">
                <papertitle>Aesthetic Text Logo Synthesis via Content-aware Layout Inferring</papertitle>
              </a>
              <br>
              <strong>Yizhi Wang</strong>,
              <a href="https://www.icst.pku.edu.cn/zlian/">Guo Pu</a>,
              <a href="https://whluo.github.io/">Wenhan Luo</a>,
              <a href="">Yexin Wang</a>,
              <a href="https://scholar.google.com/citations?user=ctLbu3IAAAAJ&hl=en&oi=ao">Pengfei Xiong</a>,
              <a href="https://scholar.google.com/citations?user=uQg2t8EAAAAJ&hl=en&oi=ao">Hongwen Kang</a>,
              <a href="https://www.icst.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em>CVPR</em>, 2020  
              <br>
							<a href="">project page</a> / 
							<a href="">arXiv</a> / 
							<a href="">video</a> /
							<a href="">code</a> / 	
              <a>will be released soon</a>	
              <p></p>
              <p>A content-aware layout generation network which takes element images and their corresponding content (such as texts) as input and synthesizes aesthetic layouts for them automatically.</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/tog21_deepvecfont.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://yizhiwang96.github.io/deepvecfont_homepage/">
                <papertitle>DeepVecFont: Synthesizing High-quality Vector Fonts via Dual-modality Learning</papertitle>
              </a>
              <br>
              <strong>Yizhi Wang</strong>,
              <a href="https://www.icst.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em>ACM Transactions on Graphics (SIGGRAPH Asia 2021 Technical Paper)</em>, 2021  
              <br>
							<a href="https://yizhiwang96.github.io/deepvecfont_homepage/">project page</a> / 
							<a href="https://arxiv.org/abs/2110.06688">arXiv</a> / 
							<a href="">video</a> /
							<a href="https://github.com/yizhiwang96/deepvecfont">code</a> / 		
              <p></p>
              <p>Directly synthesize vector fonts via dual-modality learning and differentiable rasterization (rendering), instead of vectorizing synthesized glyph images by rule-based methods.</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/tog20_attribute2font.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://hologerry.github.io/Attr2Font/">
                <papertitle>Attribute2Font: Creating Fonts You Want From Attributes</papertitle>
              </a>
              <br>
              <strong>Yizhi Wang*</strong>,  
              <a href="https://yuegao.me/">Yue Gao</a>,
              <a href="https://www.icst.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em>ACM Transactions on Graphics (SIGGRAPH 2020 Technical Paper)</em>, 2020  
              <br>
							<a href="https://yuegao.me/Attr2Font/">project page</a> / 
							<a href="https://arxiv.org/abs/2203.01913">arXiv</a> / 
							<a href="">video</a> /
							<a href="https://github.com/hologerry/Attr2Font">code</a> / 		
              <p></p>
              <p>Automatically synthesize fonts according to user-specified attributes (such as italic, serif, cursive, and angularity) and their corresponding values.</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/nerf_supervision.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://actasidiot.github.io/EFIFSTR">
                <papertitle>Exploring Font-independent Features for Scene Text Recognition</papertitle>
              </a>
              <br>
              <strong>Yizhi Wang</strong>,
              <a href="https://www.icst.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em>ACM Multimedia</em>, 2020  
              <br>
							<a href="https://actasidiot.github.io/EFIFSTR">project page</a> / 
							<a href="https://arxiv.org/abs/2009.07447">arXiv</a> / 
							<a href="">video</a> /
							<a href="https://github.com/Actasidiot/EFIFSTR">code</a> / 		
              <p></p>
              <p>Address the challenge of font variance in STR and propose a font-independent feature representation method to increase the robustness of STR models.</p>
            </td>
          </tr>
					
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/mmm18_fontrec.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.wict.pku.edu.cn/zlian/frwild/">
                <papertitle> Font Recognition in Natural Images via Transfer Learning</papertitle>
              </a>
              <br>
              <strong>Yizhi Wang</strong>,
              <a href="https://www.icst.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em>MMM</em>, 2018  
              <br>
							<a href="https://www.wict.pku.edu.cn/zlian/frwild/">project page</a> / 
							<a href="https://www.wict.pku.edu.cn/zlian/docs/20181024110641005904.pdf">Paper</a> /		
              <p></p>
              <p>Accurately recognize the font styles of texts in natural images by proposing a novel method based on deep learning and transfer learning.</p>
            </td>
          </tr>
          


        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td width="100%" valign="center">
              Merit Student, Peking University. 2018, 2021
              <br>
              Excellent Student, Wangxuan Insitute of Peking University. 2020, 2021
              <br>
              CETC The 14TH Research Institute Glarun Scholarship, Peking University. 2018
              <br>
              Excellent Award, The 17th Programming Contest of Peking University. 2018
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                template adapted from this <a href="https://jonbarron.info/">awesome website.
              </p>
            </td>
          </tr>
        </tbody></table>        
      </td>
    </tr>
  </table>
</body>

</html>
